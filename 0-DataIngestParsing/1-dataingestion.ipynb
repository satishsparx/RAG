{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a680130e",
   "metadata": {},
   "source": [
    "## Introduction to Data Ingestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "121397a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2685533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d0daf",
   "metadata": {},
   "source": [
    "## Understanding Document Datastructure in Lanchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6114f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Structure\n",
      "Document Content: This is the main content that will be embedded and searched.\n",
      "Document metadata: {'source': 'example.txt', 'author': 'satish kumar', 'page': 1}\n"
     ]
    }
   ],
   "source": [
    "## Simple document creation\n",
    "doc = Document(\n",
    "    page_content = \"This is the main content that will be embedded and searched.\",\n",
    "    metadata = {\n",
    "        \"source\": \"example.txt\",\n",
    "        \"author\": \"satish kumar\",\n",
    "        \"page\": 1\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Document Structure\")\n",
    "print(f\"Content: {doc.page_content}\")\n",
    "print(f\"Metadata: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fc0cb9",
   "metadata": {},
   "source": [
    "## Text Files (.txt) - The Simplest Case {#2-text-files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7560180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a simple text file\n",
    "import os\n",
    "os.makedirs(\"data/text_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "039f19fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text files are successfully created!!!\n"
     ]
    }
   ],
   "source": [
    "sample_txts = {\n",
    "    \"data/text_files/python_intro.txt\" : \"\"\"\n",
    "### **Introduction to Python**\n",
    "\n",
    "Python is a **high-level, interpreted, and general-purpose programming language** known for its simplicity, readability, and versatility. It was created by **Guido van Rossum** and released in **1991**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Features of Python**\n",
    "\n",
    "1. **Easy to Learn & Readable**\n",
    "\n",
    "   * Syntax is similar to English, making it beginner-friendly.\n",
    "\n",
    "2. **Interpreted Language**\n",
    "\n",
    "   * No need to compile code; it runs line by line using the Python interpreter.\n",
    "\n",
    "3. **Dynamically Typed**\n",
    "\n",
    "   * You don’t need to declare variable types explicitly.\n",
    "\n",
    "   ```python\n",
    "   x = 10   # Integer\n",
    "   x = \"Hello\"  # Now a string (no type declaration required)\n",
    "   ```\n",
    "\n",
    "4. **Cross-Platform**\n",
    "\n",
    "   * Works on Windows, macOS, Linux, and more.\n",
    "\n",
    "5. **Extensive Standard Library**\n",
    "\n",
    "   * Provides built-in modules for file handling, math, networking, etc.\n",
    "\n",
    "6. **Supports Multiple Paradigms**\n",
    "\n",
    "   * Procedural, Object-Oriented, and Functional programming.\n",
    "\n",
    "---\n",
    "\n",
    "### **Basic Python Example**\n",
    "\n",
    "```python\n",
    "# Hello World Program\n",
    "print(\"Hello, World!\")\n",
    "\n",
    "# Variables\n",
    "name = \"Alice\"\n",
    "age = 25\n",
    "print(f\"My name is {name} and I am {age} years old.\")\n",
    "\n",
    "# Simple Function\n",
    "def greet(name):\n",
    "    return f\"Hello, {name}!\"\n",
    "\n",
    "print(greet(\"Bob\"))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Where is Python Used?**\n",
    "\n",
    "* Web Development (e.g., Django, Flask)\n",
    "* Data Science & Machine Learning (e.g., NumPy, Pandas, Scikit-learn)\n",
    "* Automation & Scripting\n",
    "* Game Development\n",
    "* IoT (Internet of Things)\n",
    "* Cybersecurity & Networking\n",
    "* Artificial Intelligence (AI)\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to create a **beginner-friendly Python learning roadmap** (syntax → data types → loops → OOP → projects) or a **crash course with examples**? Or both?\n",
    "\n",
    "\"\"\",\n",
    "\"data/text_files/machinelearning_intro.txt\": \"\"\"\n",
    "  ### **Introduction to Machine Learning (ML)**\n",
    "\n",
    "**Machine Learning (ML)** is a subset of Artificial Intelligence (AI) that focuses on developing algorithms that enable computers to **learn from data** and make predictions or decisions without being explicitly programmed.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Concepts**\n",
    "\n",
    "1. **Data**\n",
    "\n",
    "   * ML models learn from historical data to identify patterns and make predictions.\n",
    "\n",
    "2. **Model**\n",
    "\n",
    "   * A mathematical representation that maps inputs to outputs based on training data.\n",
    "\n",
    "3. **Training**\n",
    "\n",
    "   * The process of teaching the model by feeding it data and adjusting parameters to minimize errors.\n",
    "\n",
    "4. **Prediction / Inference**\n",
    "\n",
    "   * Once trained, the model predicts outcomes for new, unseen data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Types of Machine Learning**\n",
    "\n",
    "1. **Supervised Learning**\n",
    "\n",
    "   * Model is trained with labeled data (input + output).\n",
    "   * Examples:\n",
    "\n",
    "     * Predicting house prices (regression).\n",
    "     * Classifying emails as spam or not (classification).\n",
    "\n",
    "2. **Unsupervised Learning**\n",
    "\n",
    "   * Model learns patterns from unlabeled data (no output provided).\n",
    "   * Examples:\n",
    "\n",
    "     * Customer segmentation (clustering).\n",
    "     * Dimensionality reduction (PCA).\n",
    "\n",
    "3. **Reinforcement Learning**\n",
    "\n",
    "   * Model learns by interacting with an environment and receiving rewards or penalties.\n",
    "   * Examples:\n",
    "\n",
    "     * Training robots to walk.\n",
    "     * Game-playing AI (e.g., AlphaGo).\n",
    "\n",
    "---\n",
    "\n",
    "### **Common Algorithms**\n",
    "\n",
    "* **Linear Regression** – Predicts continuous values.\n",
    "* **Logistic Regression** – Used for classification.\n",
    "* **Decision Trees & Random Forests** – Tree-based decision models.\n",
    "* **Support Vector Machines (SVM)** – Separates data using hyperplanes.\n",
    "* **Neural Networks** – Basis of deep learning for complex data like images, speech.\n",
    "\n",
    "---\n",
    "\n",
    "### **Applications of Machine Learning**\n",
    "\n",
    "* Recommendation systems (Netflix, Amazon)\n",
    "* Fraud detection in banking\n",
    "* Predictive maintenance in industries\n",
    "* Autonomous vehicles\n",
    "* Healthcare diagnostics\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to provide a **step-by-step roadmap to learn ML** (from Python basics → data handling → ML algorithms → projects), or a **mini crash course with Python code examples**? Or both?\n",
    "\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for filepath, content in sample_txts.items():\n",
    "    with open(filepath, 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"Text files are successfully created!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5f5d95",
   "metadata": {},
   "source": [
    "## TextLoader - Read Single File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8adfca9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'data/text_files/python_intro.txt'}, page_content='\\n### **Introduction to Python**\\n\\nPython is a **high-level, interpreted, and general-purpose programming language** known for its simplicity, readability, and versatility. It was created by **Guido van Rossum** and released in **1991**.\\n\\n---\\n\\n### **Key Features of Python**\\n\\n1. **Easy to Learn & Readable**\\n\\n   * Syntax is similar to English, making it beginner-friendly.\\n\\n2. **Interpreted Language**\\n\\n   * No need to compile code; it runs line by line using the Python interpreter.\\n\\n3. **Dynamically Typed**\\n\\n   * You don’t need to declare variable types explicitly.\\n\\n   ```python\\n   x = 10   # Integer\\n   x = \"Hello\"  # Now a string (no type declaration required)\\n   ```\\n\\n4. **Cross-Platform**\\n\\n   * Works on Windows, macOS, Linux, and more.\\n\\n5. **Extensive Standard Library**\\n\\n   * Provides built-in modules for file handling, math, networking, etc.\\n\\n6. **Supports Multiple Paradigms**\\n\\n   * Procedural, Object-Oriented, and Functional programming.\\n\\n---\\n\\n### **Basic Python Example**\\n\\n```python\\n# Hello World Program\\nprint(\"Hello, World!\")\\n\\n# Variables\\nname = \"Alice\"\\nage = 25\\nprint(f\"My name is {name} and I am {age} years old.\")\\n\\n# Simple Function\\ndef greet(name):\\n    return f\"Hello, {name}!\"\\n\\nprint(greet(\"Bob\"))\\n```\\n\\n---\\n\\n### **Where is Python Used?**\\n\\n* Web Development (e.g., Django, Flask)\\n* Data Science & Machine Learning (e.g., NumPy, Pandas, Scikit-learn)\\n* Automation & Scripting\\n* Game Development\\n* IoT (Internet of Things)\\n* Cybersecurity & Networking\\n* Artificial Intelligence (AI)\\n\\n---\\n\\nWould you like me to create a **beginner-friendly Python learning roadmap** (syntax → data types → loops → OOP → projects) or a **crash course with examples**? Or both?\\n\\n')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"data/text_files/python_intro.txt\", encoding=\"utf-8\")\n",
    "\n",
    "document = loader.load()\n",
    "\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5390ec24",
   "metadata": {},
   "source": [
    "## DirectoryLoader - Multiple Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2221d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1257.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "\n",
      " Document 1\n",
      " Source: data/text_files/python_intro.txt\n",
      " Length: 1677 characters\n",
      "\n",
      " Document 2\n",
      " Source: data/text_files/machinelearning_intro.txt\n",
      " Length: 2152 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "## Load all files in a directory\n",
    "\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"data/text_files\",\n",
    "    glob=\"**/*.txt\", # Pattern to match files\n",
    "    loader_cls= TextLoader, ##loader class\n",
    "    loader_kwargs={'encoding': 'utf-8'} ,\n",
    "    show_progress=True                \n",
    ")\n",
    "\n",
    "documents = dir_loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"\\n Document {i+1}\")\n",
    "    print(f\" Source: {doc.metadata['source']}\")\n",
    "    print(f\" Length: {len(doc.page_content)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e675786",
   "metadata": {},
   "source": [
    "## Text Splitting Strategies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e2d92b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Different document text splitters\n",
    "\n",
    "from langchain.text_splitter import (\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter,\n",
    "    RecursiveCharacterTextSplitter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750926cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 202, which is longer than the specified 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CHARACTER TEXT SPLITTER \n",
      "Created 10 chunks\n",
      "First Chunk: ### **Introduction to Python** ...\n"
     ]
    }
   ],
   "source": [
    "## Method 1: Character based splitting\n",
    "\n",
    "text = documents[0].page_content\n",
    "\n",
    "print(\" CHARACTER TEXT SPLITTER \")\n",
    "\n",
    "# Separator is applied once, not recursively.\n",
    "# If a segment exceeds chunk_size, it splits mid-text without checking for smaller separators.\n",
    "# More rigid than RecursiveTextSplitter, which better preserves logical boundaries.\n",
    "\n",
    "char_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\", # Split on new lines\n",
    "    chunk_size=200, # Max chunk size in character\n",
    "    chunk_overlap=20, # Overlap between chunks\n",
    "    length_function=len # How to measure chunk size\n",
    ")\n",
    "\n",
    "char_chunks = char_splitter.split_text(text)\n",
    "# char_chunks = char_splitter.split_documents(text)\n",
    "\n",
    "print(f\"Created {len(char_chunks)} chunks\")\n",
    "print(f\"First Chunk: {char_chunks[0][:100]} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b12504ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### **Introduction to Python**\n",
      "---------------------\n",
      "Python is a **high-level, interpreted, and general-purpose programming language** known for its simplicity, readability, and versatility. It was created by **Guido van Rossum** and released in **1991**.\n"
     ]
    }
   ],
   "source": [
    "print(char_chunks[0])\n",
    "print(\"---------------------\")\n",
    "print(char_chunks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f99f6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 13 chunks\n",
      "First Chunk: ### **Introduction to Python**\n"
     ]
    }
   ],
   "source": [
    "## Method 2: Recursive Character Splitting\n",
    "\n",
    "# In RecursiveTextSplitter, the separator hierarchy is considered first, not the chunk size.\n",
    "# Order of Operations\n",
    "# Start with the largest separator (e.g., \\n\\n for paragraphs).\n",
    "# Split text into pieces using that separator.\n",
    "# Check if each piece is smaller than or equal to chunk_size:\n",
    "# If yes, keep it as a chunk.\n",
    "# If no, recursively split the large piece using the next smaller separator (e.g., \\n for lines).\n",
    "# Repeat until:\n",
    "# A piece fits within chunk_size, or\n",
    "# No more separators remain → final fallback is splitting purely by character count.\n",
    "\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \",\"\"],\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "recursive_chunks = recursive_splitter.split_text(text)\n",
    "\n",
    "print(f\"Created {len(recursive_chunks)} chunks\")\n",
    "print(f\"First Chunk: {recursive_chunks[0][:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a954f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 13 chunks\n",
      "First Chunk: \n",
      "### **Introduction to Python**\n",
      "\n",
      "Python is a **high-level, interpreted, and general-purpose programm\n"
     ]
    }
   ],
   "source": [
    "## Token based Text splitting\n",
    "\n",
    "# A token is a unit of text used by a language model to process and generate responses. It is not the same as a word or character—it can be:\n",
    "# A whole word (e.g., \"cat\")\n",
    "# Part of a word (e.g., \"comp\", \"uter\" from \"computer\")\n",
    "# Or even punctuation or spaces (e.g., \",\", \" \")\n",
    "\n",
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size= 50, # size in tokens (not characters)\n",
    "    chunk_overlap=10\n",
    ")\n",
    "\n",
    "token_chunks = token_splitter.split_text(text)\n",
    "print(f\"Created {len(token_chunks)} chunks\")\n",
    "print(f\"First Chunk: {token_chunks[0][:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f4e72a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
